{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocRC3FcF9vU4",
        "outputId": "dcc8e1ab-9d02-49d8-808b-a5fbbef83d95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  neural-networks-data-science-uc-3-m.zip\n",
            "Zip file size: 1972451903 bytes, number of entries: 5\n",
            "-rw----     5.1 fat 243321852 bx defN 25-Jan-23 14:50 new-train-metadata.csv\n",
            "-rw----     5.1 fat       66 bx defN 25-Jan-23 14:50 sample_submission.csv\n",
            "-rw----     5.1 fat    58961 bx defN 25-Jan-23 14:50 students-test-metadata.csv\n",
            "-rw----     5.1 fat   694335 bx defN 25-Jan-23 14:50 test-image.hdf5\n",
            "-rw----     5.1 fat 2829955538 bx defN 25-Jan-23 14:50 train-image.hdf5\n",
            "5 files, 3074030752 bytes uncompressed, 1972451101 bytes compressed:  35.8%\n",
            " inflated: new-train-metadata.csv\n",
            " inflated: sample_submission.csv\n",
            " inflated: students-test-metadata.csv\n",
            " inflated: test-image.hdf5\n",
            " inflated: train-image.hdf5\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c neural-networks-data-science-uc-3-m\n",
        "\n",
        "!zipinfo neural-networks-data-science-uc-3-m.zip\n",
        "\n",
        "!jar xvf neural-networks-data-science-uc-3-m.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy6PemYu9uTo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingWarmRestarts\n",
        "from torch.amp import autocast, GradScaler\n",
        "import torch.nn.utils as nn_utils\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import warnings\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from collections import defaultdict\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "TRAIN_CSV = \"new-train-metadata.csv\"\n",
        "TRAIN_HDF5 = \"train-image.hdf5\"\n",
        "\n",
        "# Improved configuration\n",
        "POS_RATIO = 0.4  # Better balancing for minority class\n",
        "NUM_FOLDS = 5\n",
        "TOP_K = 3\n",
        "SEED = 42\n",
        "PATIENCE = 7  # Increased patience\n",
        "BATCH_SIZE = 16  # Smaller batch size for better generalization\n",
        "MAX_EPOCHS = 25  # More epochs with early stopping\n",
        "BASE_MODELS = [\n",
        "    (\"efficientnetv2_rw_s\", 384),  # More modern, stronger backbone\n",
        "    (\"convnext_small\", 384),       # Different architecture family\n",
        "    (\"eca_nfnet_l0\", 384)          # ECA-NFNet with attention\n",
        "]\n",
        "USE_SWA = False  # Disabled SWA\n",
        "AUG_STRENGTH = 0.7  # Stronger augmentations\n",
        "MIXUP_ALPHA = 0.4  # Stronger mixup\n",
        "CUTMIX_PROB = 0.3  # Add cutmix\n",
        "LABEL_SMOOTHING = 0.05  # Label smoothing\n",
        "\n",
        "# ========== DATASET ==========\n",
        "class ISIC_HDF5_MetaDataset(Dataset):\n",
        "    def __init__(self, df, hdf5_path, img_size=384, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "        self.meta = self._preprocess_metadata(df)\n",
        "\n",
        "    def _preprocess_metadata(self, df):\n",
        "        df = df.copy()\n",
        "        # Enhanced feature engineering\n",
        "        df['sex'] = LabelEncoder().fit_transform(df['sex'].fillna(\"unknown\"))\n",
        "        df['anatom_site_general'] = LabelEncoder().fit_transform(df['anatom_site_general'].fillna(\"unknown\"))\n",
        "        df['age_approx'] = df['age_approx'].fillna(df['age_approx'].median())\n",
        "\n",
        "        # Add age bins as categorical features\n",
        "        df['age_bin'] = pd.cut(df['age_approx'], bins=[0, 30, 45, 60, 75, 100], labels=False)\n",
        "\n",
        "        # Create more sophisticated feature interactions\n",
        "        base_features = df[['age_approx', 'sex', 'anatom_site_general', 'age_bin']].values\n",
        "        poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "        interactions = poly.fit_transform(base_features)\n",
        "\n",
        "        # Apply standardization\n",
        "        meta_features = StandardScaler().fit_transform(interactions)\n",
        "        return torch.tensor(meta_features, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        isic_id = row[\"isic_id\"]\n",
        "        label = torch.tensor(row[\"target\"], dtype=torch.float32)\n",
        "        meta = self.meta[idx]\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as hf:\n",
        "            encoded_bytes = hf[isic_id][()]\n",
        "        image_bgr = cv2.imdecode(encoded_bytes, cv2.IMREAD_COLOR)\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image_rgb)\n",
        "            image = transformed[\"image\"]\n",
        "        else:\n",
        "            # Default resize if no transform\n",
        "            image = cv2.resize(image_rgb, (self.img_size, self.img_size))\n",
        "            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
        "\n",
        "        return image, meta, label, isic_id\n",
        "\n",
        "# ========== ATTENTION MODULE ==========\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
        "            nn.BatchNorm2d(in_channels // 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels // 8, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_map = self.conv(x)\n",
        "        return x * attention_map\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class AdvancedModelMeta(nn.Module):\n",
        "    def __init__(self, model_name, meta_dim=18, pretrained=True):\n",
        "        super().__init__()\n",
        "        # Use more powerful backbone\n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
        "        backbone_dim = self.backbone.num_features\n",
        "\n",
        "        # Add attention mechanism\n",
        "        self.attention = SpatialAttention(backbone_dim)\n",
        "\n",
        "        # Enhanced metadata processing path\n",
        "        self.meta_fc = nn.Sequential(\n",
        "            nn.Linear(meta_dim, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Combined head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(backbone_dim + 64, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_img, x_meta):\n",
        "        # Extract image features with attention\n",
        "        img_features = self.backbone(x_img)\n",
        "        if len(img_features.shape) == 4:  # If features have spatial dimensions\n",
        "            batch_size, channels, height, width = img_features.shape\n",
        "            img_features = self.attention(img_features)\n",
        "            img_features = F.adaptive_avg_pool2d(img_features, (1, 1)).view(batch_size, channels)\n",
        "\n",
        "        # Process metadata\n",
        "        meta_features = self.meta_fc(x_meta)\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([img_features, meta_features], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# ========== LOSS ==========\n",
        "class FocalLossWithSmoothing(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, smoothing=0.05):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # Apply label smoothing\n",
        "        if self.smoothing > 0:\n",
        "            # For binary case\n",
        "            targets = targets * (1 - self.smoothing) + 0.5 * self.smoothing\n",
        "\n",
        "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-bce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "# ========== UTILS ==========\n",
        "def balance_dataset(df, pos_ratio, seed=42):\n",
        "    pos_df = df[df['target'] == 1]\n",
        "    neg_df = df[df['target'] == 0]\n",
        "    num_pos = len(pos_df)\n",
        "\n",
        "    # Dynamic ratio adjustment based on dataset size\n",
        "    # For smaller datasets, we want slightly more negative samples\n",
        "    if num_pos < 200:\n",
        "        adjusted_ratio = max(0.35, pos_ratio - 0.05)\n",
        "    else:\n",
        "        adjusted_ratio = pos_ratio\n",
        "\n",
        "    num_neg = int((num_pos * (1 - adjusted_ratio)) / adjusted_ratio)\n",
        "    neg_sample = neg_df.sample(n=min(num_neg, len(neg_df)), random_state=seed)\n",
        "    return pd.concat([pos_df, neg_sample]).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "# ========== TRANSFORMS ==========\n",
        "def get_train_transforms(img_size, aug_strength=0.7):\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(size=(img_size, img_size), scale=(0.8, 1.0)),\n",
        "        A.OneOf([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.Transpose(p=0.5),\n",
        "        ], p=aug_strength),\n",
        "        A.OneOf([\n",
        "            A.MotionBlur(blur_limit=3, p=0.2),\n",
        "            A.MedianBlur(blur_limit=3, p=0.3),\n",
        "            A.GaussianBlur(blur_limit=3, p=0.3),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
        "        ], p=aug_strength*0.7),\n",
        "        A.OneOf([\n",
        "            A.OpticalDistortion(p=0.3),\n",
        "            A.GridDistortion(p=0.2),\n",
        "            A.ElasticTransform(p=0.2),\n",
        "        ], p=aug_strength*0.5),\n",
        "        A.OneOf([\n",
        "            A.CLAHE(clip_limit=2, p=0.5),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "            A.RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, p=0.5),\n",
        "        ], p=aug_strength*0.8),\n",
        "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=2, p=aug_strength*0.3),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_valid_transforms(img_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "# ========== AUGMENTATION STRATEGIES ==========\n",
        "def mixup_data(x, meta, y, alpha=0.4):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    mixed_meta = lam * meta + (1 - lam) * meta[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, mixed_meta, y_a, y_b, lam\n",
        "\n",
        "def cutmix_data(x, meta, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        return x, meta, y, y, 1.0\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    # Get cutmix dimensions\n",
        "    h, w = x.shape[2], x.shape[3]\n",
        "    cut_h, cut_w = int(h * np.sqrt(1 - lam)), int(w * np.sqrt(1 - lam))\n",
        "    cy, cx = np.random.randint(h), np.random.randint(w)\n",
        "\n",
        "    # Get bounding box\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, w)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, h)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, w)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, h)\n",
        "\n",
        "    # Apply cutmix to images\n",
        "    x_mixed = x.clone()\n",
        "    x_mixed[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n",
        "\n",
        "    # Update lambda to reflect actual area ratio\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (h * w))\n",
        "\n",
        "    # Mix metadata too (like mixup)\n",
        "    meta_mixed = lam * meta + (1 - lam) * meta[index, :]\n",
        "\n",
        "    return x_mixed, meta_mixed, y, y[index], lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "# ========== TRAINING ==========\n",
        "def train_fold(model_config, fold, train_idx, val_idx, df):\n",
        "    model_name, img_size = model_config\n",
        "\n",
        "    print(f\"Training {model_name} with image size {img_size} on fold {fold}\")\n",
        "\n",
        "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = ISIC_HDF5_MetaDataset(\n",
        "        train_df, TRAIN_HDF5, img_size=img_size,\n",
        "        transform=get_train_transforms(img_size, AUG_STRENGTH)\n",
        "    )\n",
        "    val_dataset = ISIC_HDF5_MetaDataset(\n",
        "        val_df, TRAIN_HDF5, img_size=img_size,\n",
        "        transform=get_valid_transforms(img_size)\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Get the number of metadata features dynamically from the dataset\n",
        "    meta_dim = train_dataset.meta.shape[1]\n",
        "\n",
        "    model = AdvancedModelMeta(model_name, meta_dim=meta_dim).to(device)\n",
        "\n",
        "    # Enhanced loss with label smoothing\n",
        "    criterion = FocalLossWithSmoothing(\n",
        "        alpha=0.25, gamma=2.0, smoothing=LABEL_SMOOTHING\n",
        "    )\n",
        "\n",
        "    # Different learning rates for backbone and new layers\n",
        "    param_groups = [\n",
        "        {'params': model.backbone.parameters(), 'lr': 2e-5},\n",
        "        {'params': model.attention.parameters(), 'lr': 5e-4},\n",
        "        {'params': model.meta_fc.parameters(), 'lr': 4e-4},\n",
        "        {'params': model.head.parameters(), 'lr': 4e-4}\n",
        "    ]\n",
        "\n",
        "    optimizer = optim.AdamW(param_groups, weight_decay=1e-4)\n",
        "\n",
        "    # LR scheduler - Cosine annealing with warm restarts\n",
        "    scheduler = CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=5, T_mult=1, eta_min=1e-6\n",
        "    )\n",
        "\n",
        "    # Mixed precision for faster training\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_auc = 0\n",
        "    no_improve_epochs = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(1, MAX_EPOCHS + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for x_img, x_meta, y, _ in tqdm(train_loader, desc=f\"Fold {fold} | Epoch {epoch}\"):\n",
        "            x_img, x_meta, y = x_img.to(device), x_meta.to(device), y.to(device)\n",
        "\n",
        "            # Apply mixup or cutmix with probability\n",
        "            rand_prob = np.random.random()\n",
        "            if rand_prob < 0.4:  # 40% chance for mixup\n",
        "                x_img, x_meta, y_a, y_b, lam = mixup_data(x_img, x_meta, y, alpha=MIXUP_ALPHA)\n",
        "                aug_type = \"mixup\"\n",
        "            elif rand_prob < 0.6:  # 20% chance for cutmix\n",
        "                x_img, x_meta, y_a, y_b, lam = cutmix_data(x_img, x_meta, y, alpha=MIXUP_ALPHA)\n",
        "                aug_type = \"cutmix\"\n",
        "            else:  # 40% no mixing\n",
        "                y_a, y_b, lam = y, y, 1.0\n",
        "                aug_type = \"none\"\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(device_type=device.type if device.type != 'mps' else 'cpu'):\n",
        "                logits = model(x_img, x_meta).view(-1)\n",
        "                if aug_type != \"none\":\n",
        "                    loss = mixup_criterion(criterion, logits, y_a, y_b, lam)\n",
        "                else:\n",
        "                    loss = criterion(logits, y)\n",
        "\n",
        "            # Use gradient scaling with mixed precision\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            nn_utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        probs, targets = [], []\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_img, x_meta, y, _ in val_loader:\n",
        "                x_img, x_meta, y = x_img.to(device), x_meta.to(device), y.to(device)\n",
        "\n",
        "                with autocast(device_type=device.type if device.type != 'mps' else 'cpu'):\n",
        "                    logits = model(x_img, x_meta).view(-1)\n",
        "                    loss = criterion(logits, y)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                preds = torch.sigmoid(logits).cpu().numpy()\n",
        "                probs.extend(preds)\n",
        "                targets.extend(y.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        auc = roc_auc_score(targets, probs)\n",
        "\n",
        "        history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': avg_train_loss,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'auc': auc\n",
        "        })\n",
        "\n",
        "        print(f\"Fold {fold} | Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | AUC: {auc:.4f}\")\n",
        "\n",
        "        # Save model on improved performance\n",
        "        if auc > best_auc:\n",
        "            best_auc = auc\n",
        "            # Include model name in the saved file\n",
        "            model_path = f\"{model_name}_fold{fold}.pt\"\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"✅ Saved model to {model_path} with AUC {auc:.4f}\")\n",
        "            no_improve_epochs = 0\n",
        "        else:\n",
        "            no_improve_epochs += 1\n",
        "            if no_improve_epochs >= PATIENCE:\n",
        "                print(f\"⛔ Early stopping on epoch {epoch} for fold {fold}\")\n",
        "                break\n",
        "\n",
        "    # Save training history\n",
        "    history_df = pd.DataFrame(history)\n",
        "    history_df.to_csv(f\"history_{model_name}_fold{fold}.csv\", index=False)\n",
        "\n",
        "    return best_auc, model_name\n",
        "\n",
        "# ========== MAIN ==========\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"Loading data from {TRAIN_CSV}\")\n",
        "\n",
        "    df = pd.read_csv(TRAIN_CSV)\n",
        "    print(f\"Original dataset size: {len(df)}\")\n",
        "\n",
        "    # Balance dataset\n",
        "    df = balance_dataset(df, pos_ratio=POS_RATIO, seed=SEED)\n",
        "    print(f\"Balanced dataset size: {len(df)}\")\n",
        "\n",
        "    # Set up cross-validation\n",
        "    skf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "    # Dictionary to track performance across models and folds\n",
        "    results = defaultdict(list)\n",
        "\n",
        "    # Train each model architecture on each fold\n",
        "    for model_config in BASE_MODELS:\n",
        "        model_name = model_config[0]\n",
        "        print(f\"\\n{'='*20} Training {model_name} {'='*20}\")\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
        "            print(f\"\\n{'='*20} {model_name} - Fold {fold} {'='*20}\")\n",
        "            auc, model_name = train_fold(model_config, fold, train_idx, val_idx, df)\n",
        "            results[model_name].append(auc)\n",
        "\n",
        "    # Save results for all models and folds\n",
        "    all_results = []\n",
        "    for model_name, aucs in results.items():\n",
        "        for fold, auc in enumerate(aucs):\n",
        "            all_results.append({\n",
        "                'model': model_name,\n",
        "                'fold': fold,\n",
        "                'auc': auc\n",
        "            })\n",
        "\n",
        "    pd.DataFrame(all_results).to_csv(\"all_fold_results.csv\", index=False)\n",
        "\n",
        "    # For each model, select top K folds\n",
        "    top_folds = {}\n",
        "    for model_name, aucs in results.items():\n",
        "        top_idx = np.argsort(aucs)[-TOP_K:][::-1]\n",
        "        top_folds[model_name] = top_idx.tolist()\n",
        "\n",
        "        # Write top folds to file\n",
        "        with open(f\"top_folds_{model_name}.txt\", \"w\") as f:\n",
        "            for fold in top_idx:\n",
        "                f.write(f\"{fold}\\n\")\n",
        "\n",
        "        print(f\"\\n✅ {model_name} - Best folds: {top_idx.tolist()} with AUCs: {[aucs[i] for i in top_idx]}\")\n",
        "\n",
        "    print(\"\\n✅ Training complete!\")\n",
        "    print(f\"Results saved to all_fold_results.csv\")\n",
        "    print(f\"Top folds saved to top_folds_<model_name>.txt files\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import h5py\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=pd.errors.DtypeWarning)\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "TEST_CSV = \"students-test-metadata.csv\"\n",
        "TEST_HDF5 = \"test-image.hdf5\"\n",
        "OUTPUT_CSV = \"predictions.csv\"\n",
        "\n",
        "# Configuración para inferencia\n",
        "BATCH_SIZE = 16\n",
        "TOP_K = 3  # Usar los K mejores folds de cada modelo para ensemble\n",
        "\n",
        "BASE_MODELS = [\n",
        "    (\"efficientnetv2_rw_s\", 384),\n",
        "    (\"convnext_small\", 384),\n",
        "    (\"eca_nfnet_l0\", 384)\n",
        "]\n",
        "\n",
        "MODEL_WEIGHTS = {\n",
        "    \"efficientnetv2_rw_s\": 1.0,  # Ajusta estos valores según el rendimiento en validación\n",
        "    \"convnext_small\": 1.2,\n",
        "    \"eca_nfnet_l0\": 0.8\n",
        "}\n",
        "# ========== ATTENTION MODULE ==========\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // 8, kernel_size=1),\n",
        "            nn.BatchNorm2d(in_channels // 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels // 8, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_map = self.conv(x)\n",
        "        return x * attention_map\n",
        "\n",
        "# ========== MODEL ==========\n",
        "class AdvancedModelMeta(nn.Module):\n",
        "    def __init__(self, model_name, meta_dim=18, pretrained=False):\n",
        "        super().__init__()\n",
        "        # Backbone\n",
        "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
        "        backbone_dim = self.backbone.num_features\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = SpatialAttention(backbone_dim)\n",
        "\n",
        "        # Metadata processing path\n",
        "        self.meta_fc = nn.Sequential(\n",
        "            nn.Linear(meta_dim, 256),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LayerNorm(64),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Combined head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(backbone_dim + 64, 128),\n",
        "            nn.LayerNorm(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_img, x_meta):\n",
        "        # Extract image features with attention\n",
        "        img_features = self.backbone(x_img)\n",
        "        if len(img_features.shape) == 4:  # If features have spatial dimensions\n",
        "            batch_size, channels, height, width = img_features.shape\n",
        "            img_features = self.attention(img_features)\n",
        "            img_features = F.adaptive_avg_pool2d(img_features, (1, 1)).view(batch_size, channels)\n",
        "\n",
        "        # Process metadata\n",
        "        meta_features = self.meta_fc(x_meta)\n",
        "\n",
        "        # Combine features\n",
        "        combined = torch.cat([img_features, meta_features], dim=1)\n",
        "        return self.head(combined)\n",
        "\n",
        "# ========== DATASET ==========\n",
        "class ISIC_HDF5_TestDataset(Dataset):\n",
        "    def __init__(self, df, hdf5_path, img_size=384, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.hdf5_path = hdf5_path\n",
        "        self.transform = transform\n",
        "        self.img_size = img_size\n",
        "        self.meta = self._preprocess_metadata(df)\n",
        "\n",
        "    def _preprocess_metadata(self, df):\n",
        "        df = df.copy()\n",
        "        # Apply the same preprocessing as in training\n",
        "        df['sex'] = LabelEncoder().fit_transform(df['sex'].fillna(\"unknown\"))\n",
        "        df['anatom_site_general'] = LabelEncoder().fit_transform(df['anatom_site_general'].fillna(\"unknown\"))\n",
        "        df['age_approx'] = df['age_approx'].fillna(df['age_approx'].median())\n",
        "\n",
        "        # Add age bins as categorical features\n",
        "        df['age_bin'] = pd.cut(df['age_approx'], bins=[0, 30, 45, 60, 75, 100], labels=False)\n",
        "\n",
        "        # Create feature interactions\n",
        "        base_features = df[['age_approx', 'sex', 'anatom_site_general', 'age_bin']].values\n",
        "        poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "        interactions = poly.fit_transform(base_features)\n",
        "\n",
        "        # Apply standardization\n",
        "        meta_features = StandardScaler().fit_transform(interactions)\n",
        "        return torch.tensor(meta_features, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        isic_id = row[\"isic_id\"]\n",
        "        meta = self.meta[idx]\n",
        "\n",
        "        with h5py.File(self.hdf5_path, 'r') as hf:\n",
        "            encoded_bytes = hf[isic_id][()]\n",
        "        image_bgr = cv2.imdecode(encoded_bytes, cv2.IMREAD_COLOR)\n",
        "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image_rgb)\n",
        "            image = transformed[\"image\"]\n",
        "        else:\n",
        "            # Default resize if no transform\n",
        "            image = cv2.resize(image_rgb, (self.img_size, self.img_size))\n",
        "            image = torch.from_numpy(image.transpose(2, 0, 1)).float() / 255.0\n",
        "\n",
        "        return image, meta, isic_id\n",
        "\n",
        "# ========== TEST TIME AUGMENTATION ==========\n",
        "def tta_inference(model, img, meta, tta_transforms, device):\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    # Original prediction\n",
        "    with torch.no_grad():\n",
        "        pred = torch.sigmoid(model(img.to(device), meta.to(device))).cpu().numpy()\n",
        "    probs.append(pred)\n",
        "\n",
        "    # Test-time augmentations\n",
        "    for transform in tta_transforms:\n",
        "        aug_img = transform(img.cpu()).to(device)\n",
        "        with torch.no_grad():\n",
        "            aug_pred = torch.sigmoid(model(aug_img, meta.to(device))).cpu().numpy()\n",
        "        probs.append(aug_pred)\n",
        "\n",
        "    # Average predictions\n",
        "    return np.mean(probs, axis=0)\n",
        "\n",
        "# ========== TRANSFORMS ==========\n",
        "def get_test_transforms(img_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_tta_transforms():\n",
        "    tta_transforms = [\n",
        "        lambda x: torch.flip(x, dims=[-1]),  # Horizontal flip\n",
        "        lambda x: torch.flip(x, dims=[-2]),  # Vertical flip\n",
        "        lambda x: torch.rot90(x, k=1, dims=[-2, -1]),  # 90 degree rotation\n",
        "        lambda x: torch.rot90(x, k=2, dims=[-2, -1]),  # 180 degree rotation\n",
        "    ]\n",
        "    return tta_transforms\n",
        "\n",
        "# ========== LOAD TOP FOLDS ==========\n",
        "def get_top_folds():\n",
        "    top_folds_dict = {}\n",
        "    for model_name, _ in BASE_MODELS:\n",
        "        try:\n",
        "            with open(f\"top_folds_{model_name}.txt\", \"r\") as f:\n",
        "                top_folds = [int(line.strip()) for line in f.readlines()]\n",
        "                top_folds_dict[model_name] = top_folds[:TOP_K]\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: Could not find top folds file for {model_name}. Using folds 0-{TOP_K-1}.\")\n",
        "            top_folds_dict[model_name] = list(range(TOP_K))\n",
        "    return top_folds_dict\n",
        "\n",
        "\n",
        "# ========== INFERENCE ==========\n",
        "def run_inference():\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"Loading test data from {TEST_CSV}\")\n",
        "\n",
        "    df_test = pd.read_csv(TEST_CSV)\n",
        "    print(f\"Test dataset size: {len(df_test)}\")\n",
        "\n",
        "    # Prepare top folds for each model\n",
        "    top_folds_dict = get_top_folds()\n",
        "    print(\"Top folds for each model:\")\n",
        "    for model_name, folds in top_folds_dict.items():\n",
        "        print(f\"  - {model_name}: {folds}\")\n",
        "\n",
        "    # Create test dataset and dataloader\n",
        "    test_predictions = {}\n",
        "\n",
        "    # Run inference for each model and fold\n",
        "    for model_config in BASE_MODELS:\n",
        "        model_name, img_size = model_config\n",
        "        print(f\"\\n{'='*20} Inference for {model_name} {'='*20}\")\n",
        "\n",
        "        # Create dataset with appropriate image size\n",
        "        test_dataset = ISIC_HDF5_TestDataset(\n",
        "            df_test, TEST_HDF5, img_size=img_size,\n",
        "            transform=get_test_transforms(img_size)\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "            num_workers=2, pin_memory=True\n",
        "        )\n",
        "\n",
        "        # Load the models for this architecture\n",
        "        fold_predictions = {}\n",
        "\n",
        "        for fold in top_folds_dict[model_name]:\n",
        "            print(f\"Loading {model_name} - Fold {fold}\")\n",
        "\n",
        "            # Get meta dimension from the dataset\n",
        "            meta_dim = test_dataset.meta.shape[1]\n",
        "\n",
        "            # Initialize model\n",
        "            model = AdvancedModelMeta(model_name, meta_dim=meta_dim).to(device)\n",
        "\n",
        "            # Try to load model weights\n",
        "            try:\n",
        "                model.load_state_dict(torch.load(f\"{model_name}_fold{fold}.pt\", map_location=device))\n",
        "                print(f\"✅ Loaded model from {model_name}_fold{fold}.pt\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"⚠️ Could not find weights for {model_name} fold {fold}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            # Get TTA transforms\n",
        "            tta_transforms = get_tta_transforms()\n",
        "\n",
        "            # Run inference with TTA\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_ids = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, meta, isic_ids in tqdm(test_loader, desc=f\"Predicting with {model_name} fold {fold}\"):\n",
        "                    images = images.to(device)\n",
        "                    meta = meta.to(device)\n",
        "\n",
        "                    # Apply TTA\n",
        "                    batch_preds = tta_inference(model, images, meta, tta_transforms, device)\n",
        "\n",
        "                    all_preds.extend(batch_preds.flatten().tolist())\n",
        "                    all_ids.extend(isic_ids)\n",
        "\n",
        "            # Store predictions for this fold\n",
        "            for idx, pred in zip(all_ids, all_preds):\n",
        "                if idx not in fold_predictions:\n",
        "                    fold_predictions[idx] = []\n",
        "                fold_predictions[idx].append(pred)\n",
        "\n",
        "        # Average predictions across folds for this model\n",
        "        for idx, preds in fold_predictions.items():\n",
        "            if idx not in test_predictions:\n",
        "                test_predictions[idx] = []\n",
        "            test_predictions[idx].append(np.mean(preds))\n",
        "\n",
        "    \"\"\"# Average predictions across all models\n",
        "    final_predictions = {}\n",
        "    for idx, preds in test_predictions.items():\n",
        "        final_predictions[idx] = np.mean(preds)\"\"\"\n",
        "\n",
        "    def weighted_ensemble_prediction(predictions_dict, model_weights):\n",
        "    #Ensemble ponderado usando los pesos especificados para cada modelo\n",
        "      final_predictions = {}\n",
        "\n",
        "      for isic_id, model_preds in predictions_dict.items():\n",
        "          weighted_sum = 0\n",
        "          total_weight = 0\n",
        "\n",
        "          for model_idx, pred in enumerate(model_preds):\n",
        "              model_name = BASE_MODELS[model_idx][0]\n",
        "              weight = MODEL_WEIGHTS.get(model_name, 1.0)\n",
        "\n",
        "              weighted_sum += pred * weight\n",
        "              total_weight += weight\n",
        "\n",
        "          final_predictions[isic_id] = weighted_sum / total_weight\n",
        "\n",
        "      return final_predictions\n",
        "\n",
        "    final_predictions = weighted_ensemble_prediction(test_predictions, MODEL_WEIGHTS)\n",
        "\n",
        "    # Create submission dataframe\n",
        "    submission = pd.DataFrame({\n",
        "        'isic_id': list(final_predictions.keys()),\n",
        "        'target': list(final_predictions.values())\n",
        "    })\n",
        "\n",
        "    submission.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"✅ Predictions saved to {OUTPUT_CSV}\")\n",
        "    print(f\"Total predictions: {len(submission)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_inference()"
      ],
      "metadata": {
        "id": "cxCnl_u--xTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}